# Cfg for Example: switching between sim and real reach task
world:
  type: 'Bullet'
  robot: 'panda'
  controlType: "EEPosture"
data_dir: 'data'
# Simulation parameters
sim_params:
  time_step: 0.001 #0.004166  # 1./240.
  MAX_STEPS: 500

policy_freq: 20 # For gazebo?
control_freq: 500 # Hz

# Robots are specified by types and urdf locations
# also may include intial setup like poses and orientations
!include ../../cfg/sawyer.yaml
!include ../../cfg/panda.yaml
!include ../../cfg/table_and_bin.yaml

# Default controllers for each robot.
!include ../../cfg/default_sawyer_controller.yaml
!include ../../cfg/default_panda_controller.yaml
scene_objects:
  ['table', 'bin']

sensor:
  camera:
    name:
        'camera'
    image:
      height: 224
      width: 224
    extrinsics:
        eye_position:
          [0.6, 0.0, 1.0]
        target_position:
          [0.6, 0., 0]
        up_vector:
          [1., 0., 1.]
    intrinsics:
        fov: 60
        near_plane: 0.02
        far_plane: 100
    # Parameters for randomization
    random:
      randomize: True
      extrinsics:
        eye_position:
          lower:
            [0.6, 0., 1.75]
          upper:
            [0.6, 0., 1.75]
        target_position:
          lower:
            [0.6, 0., 0]
          upper:
            [0.6, 0., 0]
      intrinsics:
        fov:
          lower: 50
          upper: 80
        near_plane:
          lower: 0.01
          upper: 0.05
        far_plane:
          lower: 10
          upper: 150

object:
  object_dict:
    object_0:
      name:
        '013_apple'
      count:
        1
      path:
        'objects/ycb/013_apple/google_16k/textured.urdf'
      position: [1.5, 0, 0]
      orientation: [0,0,0]
      is_static: True
      scale: 1.0
      default_position: [0.7, 0.1, 0.03] #z  = 0.1
  default_position: [0.7, 0.1, 0.03] #z  = 0.1
  random:
    randomize: True
    position:
      lower:
        [0.3, -0.2, 0.1]
      upper:
        [0.7, 0.2, 0.1]


# Perception and Learning
env:
  observation_space:
    low:
      [-2.0, -2.0, -2.0]
    high:
      [2.0, 2.0, 2.0]
  action_space:
    low: [-1.0, -1.0, -1.0]
    high: [1.0, 1.0, 1.0]

learning_parms:
  hyperparameters:
  learning_rate:


vision_params:
  segmentation:
